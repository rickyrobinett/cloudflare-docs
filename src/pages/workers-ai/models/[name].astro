---
import type { GetStaticPaths, MarkdownHeading } from "astro";
import { getCollection } from "astro:content";
import StarlightPage, {
	type StarlightPageProps,
} from "@astrojs/starlight/components/StarlightPage.astro";
import { LinkButton, Tabs, TabItem, Code, Aside, Badge } from "~/components";
import ModelInfo from "~/components/models/ModelInfo.tsx";
import ModelBadges from "~/components/models/ModelBadges.tsx";
import SchemaViewer from "~/components/models/SchemaViewer.astro";

import TextGenerationCode from "~/components/models/code/TextGenerationCode.astro";
import AutomaticSpeechRecognitionCode from "~/components/models/code/AutomaticSpeechRecognitionCode.astro";
import ImageClassificationCode from "~/components/models/code/ImageClassificationCode.astro";
import ImageToTextCode from "~/components/models/code/ImageToTextCode.astro";
import ObjectDetectionCode from "~/components/models/code/ObjectDetectionCode.astro";
import SummarizationCode from "~/components/models/code/SummarizationCode.astro";
import TextClassificationCode from "~/components/models/code/TextClassificationCode.astro";
import TextEmbeddingCode from "~/components/models/code/TextEmbeddingCode.astro";
import TextToImageCode from "~/components/models/code/TextToImageCode.astro";
import TranslationCode from "~/components/models/code/TranslationCode.astro";
import StableDiffusionV15Img2ImgCode from "~/components/models/code/StableDiffusion-v1-5-img2imgCode.astro";
import StableDiffusionV15InpaintingCode from "~/components/models/code/StableDiffusion-v1-5-inpaintingCode.astro";
import Flux1Schnell from "~/components/models/code/Flux-1-Schnell.astro";
import WhisperBase64Code from "~/components/models/code/WhisperBase64Code.astro";

import { authorData } from "~/components/models/data";

export const getStaticPaths = (async () => {
	const models = await getCollection("workers-ai-models");

	return models.map((entry) => {
		return {
			params: {
				name: entry.data.name.split("/")[2],
			},
			props: { model: entry.data },
		};
	});
}) satisfies GetStaticPaths;

const { name } = Astro.params;
const { model } = Astro.props;

let CodeExamples = null;
switch (model.task.name) {
	case "Text Generation":
		CodeExamples = TextGenerationCode;
		break;
	case "Automatic Speech Recognition":
		CodeExamples = AutomaticSpeechRecognitionCode;
		break;
	case "Image Classification":
		CodeExamples = ImageClassificationCode;
		break;
	case "Object Detection":
		CodeExamples = ObjectDetectionCode;
		break;
	case "Image-to-Text":
		CodeExamples = ImageToTextCode;
		break;
	case "Text-to-Image":
		CodeExamples = TextToImageCode;
		break;
	case "Translation":
		CodeExamples = TranslationCode;
		break;
	case "Summarization":
		CodeExamples = SummarizationCode;
		break;
	case "Text Embedding":
		CodeExamples = TextEmbeddingCode;
		break;
	case "Text Classification":
		CodeExamples = TextClassificationCode;
		break;
}

// Overrides
if (model.name === "@cf/runwayml/stable-diffusion-v1-5-img2img") {
	CodeExamples = StableDiffusionV15Img2ImgCode;
}

if (model.name === "@cf/runwayml/stable-diffusion-v1-5-inpainting") {
	CodeExamples = StableDiffusionV15InpaintingCode;
}

if (model.name === "@cf/black-forest-labs/flux-1-schnell") {
	CodeExamples = Flux1Schnell;
}

if (model.name === "@cf/openai/whisper-large-v3-turbo") {
	CodeExamples = WhisperBase64Code;
}

const description = model.description;
const terms = model.properties.find((x) => x.property_id === "terms");

const isBeta = model.properties.find(
	({ property_id, value }) => property_id === "beta" && value === "true",
);

const hasPlayground = model.task.name === "Text Generation";

const author = (authorData as any)[model.name.split("/")[1]];

// Strong type coercion needed due to Starlight's component override for hideTitle
const starlightPageProps = {
	frontmatter: {
		title: name,
		description,
	},
	headings: [
		hasPlayground
			? { depth: 2, slug: "Playground", text: "Playground" }
			: false,
		CodeExamples ? { depth: 2, slug: "Usage", text: "Usage" } : false,
		{ depth: 2, slug: "Parameters", text: "Parameters" },
		{ depth: 3, slug: "Input", text: "Input" },
		{ depth: 3, slug: "Output", text: "Output" },
		{ depth: 2, slug: "API Schemas", text: "API Schemas" },
	].filter((v) => Boolean(v)) as MarkdownHeading[],
	hideTitle: true,
} as StarlightPageProps;
---

<StarlightPage {...starlightPageProps}>
	<div class="align-center flex">
		{
			author ? (
				<img
					class="mr-4 block h-12 w-12"
					src={author.logo}
					alt={`${author.name} logo`}
				/>
			) : (
				<div class="mr-4 flex h-12 w-12 items-center justify-center rounded-md bg-gray-100 text-2xl font-black uppercase text-gray-400">
					{model.name.split("/")[1].substring(0, 1)}
				</div>
			)
		}
		<div>
			<h1
				id="_top"
				class="!-mt-4 !mb-0 flex items-center !text-4xl !font-bold !leading-none"
			>
				{name}
				{isBeta && <Badge text="Beta" variant="caution" class="ml-3 mt-2" />}
			</h1>
			<span class="-mt-1 block"><ModelInfo model={model} /></span>
		</div>
	</div>

	<span class="mt-4 block font-mono text-sm text-gray-400">{model.name}</span>

	<p class="!mb-2 mt-3">{description}</p>
	{terms && <a href={terms.value}>Terms and License</a>}
	<ModelBadges model={model} />

	{
		model.name === "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b" && (
			<Aside>
				<p>
					This model has a specialized pricing structure that's separate from
					the standard Workers AI pricing plan. The pricing for
					<code>@cf/deepseek-ai/deepseek-r1-distill-qwen-32b</code> is:
					<ul>
						<li>$0.50 per 1M input token</li>
						<li>$4.88 per 1M output token</li>
					</ul>
				</p>
			</Aside>
		)
	}
	{
		model.name === "@cf/meta/llama-3.2-11b-vision-instruct" && (
			<Aside>
				<p>
					To use Llama 3.2 11b Vision Instruct, you need to agree to the{" "}
					<a href="https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/LICENSE">
						Meta License
					</a>{" "}
					and{" "}
					<a href="https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/USE_POLICY.md">
						Acceptable Use Policy
					</a>
					. To do so, please send an initial request to
					<code>@cf/meta/llama-3.2-11b-vision-instruct</code> with
					<code>"prompt" : "agree"</code>. After that, you'll be able to use the
					model as normal.
				</p>
				<Code
					code={`curl https://api.cloudflare.com/client/v4/accounts/$CLOUDFLARE_ACCOUNT_ID/ai/run/@cf/meta/llama-3.2-11b-vision-instruct \\
   -X POST \\
   -H "Authorization: Bearer $CLOUDFLARE_AUTH_TOKEN" \\
   -d '{ "prompt": "agree"}'`}
					lang="sh"
				/>
			</Aside>
		)
	}

	{
		hasPlayground && (
			<>
				<h2 id="Playground">Playground</h2>
				<p>
					Try out this model with Workers AI LLM Playground. It does not require
					any setup or authentication and an instant way to preview and test a
					model directly in the browser.
				</p>
				<LinkButton
					href={`https://playground.ai.cloudflare.com/?model=${model.name}`}
				>
					Launch the LLM Playground
				</LinkButton>
			</>
		)
	}

	{
		CodeExamples && (
			<>
				<h2 id="Usage">Usage</h2>
				<CodeExamples name={model.name} lora={false} />
			</>
		)
	}

	<h2 id="Parameters">Parameters</h2>
	<p><span class="text-red-500">*</span> indicates a required field</p>
	<h3 id="Input">Input</h3>
	<SchemaViewer schema={model.schema.input} />

	<h3 id="Output">Output</h3>
	<SchemaViewer schema={model.schema.output} />

	<h2 id="API Schemas">API Schemas</h2>
	<p>The following schemas are based on JSON Schema</p>

	<Tabs>
		<TabItem label="Input">
			<Code code={JSON.stringify(model.schema.input, null, 4)} lang="json" />
		</TabItem>
		<TabItem label="Output">
			<Code code={JSON.stringify(model.schema.output, null, 4)} lang="json" />
		</TabItem>
	</Tabs>
</StarlightPage>
